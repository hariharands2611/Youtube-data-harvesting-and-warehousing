{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa8ae290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pymongo\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "65b8c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Api connection\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "api_key=\"AIzaSyC8Z8VsWmFNJFgreeduOMTvTa_4fVWszfc\"\n",
    "youtube = googleapiclient.discovery.build(api_service_name, api_version,developerKey= api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8ededd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel information\n",
    "def get_channel_detail(channel_id):\n",
    "    request = youtube.channels().list(part=\"snippet,contentDetails,statistics\",id=channel_id)\n",
    "    response = request.execute()\n",
    "    for i in response.get('items',[]):\n",
    "        snippet=i.get('snippet',{})\n",
    "        contentDetails=i.get('contentDetails',{})\n",
    "        statistics=i.get('statistics',{})\n",
    "        data={\n",
    "            \"channel_name\":snippet.get('title',''),\n",
    "            \"Channel_ID\":i.get('id',''),\n",
    "            \"Subscription_Count\":statistics.get('subscriberCount',''),\n",
    "            \"Channel_Views\":statistics.get('viewCount',''),\n",
    "            \"Channel_Description\":snippet.get('description',''),\n",
    "            \"Video_count\":statistics.get('videoCount',''),\n",
    "            \"Playlist_id\":contentDetails.get('relatedPlaylists',{}).get('uploads','')}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3a69f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_ids\n",
    "def get_video_id(channel_id):\n",
    "    video_ids = []\n",
    "    request = youtube.channels().list(part=\"contentDetails\",id=channel_id)\n",
    "    response = request.execute()\n",
    "    playlist_id=response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    next_page_token= None\n",
    "    while True:\n",
    "            response1=youtube.playlistItems().list(part='snippet',playlistId=playlist_id,maxResults=50,pageToken=next_page_token).execute()\n",
    "            for i in range(len(response1['items'])):\n",
    "                video_ids.append(response1['items'][i]['snippet']['resourceId']['videoId'])\n",
    "            next_page_token=response1.get('nextPageToken')\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "    return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a9898200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video information\n",
    "def get_video_detail(video_ids):\n",
    "    video_data = []\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        for item in response.get('items', []):\n",
    "            snippet = item.get('snippet', {})\n",
    "            statistics = item.get('statistics', {})\n",
    "            content_details = item.get('contentDetails', {})\n",
    "            data1 = {\n",
    "                'Channel_Id': snippet.get('channelId', ''),\n",
    "                'Channel_Name': snippet.get('channelTitle', ''),\n",
    "                'Video_Id': item.get('id', ''),\n",
    "                'Video_Name': snippet.get('title', ''),\n",
    "                'Video_Description': snippet.get('description', ''),\n",
    "                'Published_Date': snippet.get('publishedAt', ''),\n",
    "                'View_Count': statistics.get('viewCount', ''),\n",
    "                'Like_Count': statistics.get('likeCount', ''),\n",
    "                'Favorite_Count': statistics.get('favoriteCount', 0),\n",
    "                'Comment': statistics.get('commentCount', 0),\n",
    "                'Duration': content_details.get('duration', ''),\n",
    "                'Thumbnail': snippet.get('thumbnails', {}).get('default', {}).get('url', ''),\n",
    "                'Caption_status': content_details.get('caption', '')\n",
    "            }\n",
    "            video_data.append(data1)\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1ea83fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment information\n",
    "def get_comment_detail(video_ids):\n",
    "    comment_data=[]\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request=youtube.commentThreads().list(\n",
    "            part=\"snippet,replies\",videoId=video_id,\n",
    "            maxResults=50)\n",
    "            response3=request.execute()\n",
    "            for item in response3.get('items',[]):\n",
    "                snippet=item.get('snippet',{})\n",
    "                replies=item.get('replies',{})\n",
    "                data2= {\"Channel_Id\":snippet.get(\"channelId\",''),\n",
    "                        \"comment_id\":item.get('id',''),\n",
    "                        \"Video_id\":snippet.get('videoId',''),\n",
    "                        \"Comment_Text\":snippet.get('topLevelComment',{}).get('snippet',{}).get('textDisplay',''),\n",
    "                        \"Comment_Author\":snippet.get('topLevelComment',{}).get('snippet',{}).get('authorDisplayName',''),\n",
    "                        \"Comment_PublishedAt\":snippet.get('topLevelComment',{}).get('snippet',{}).get('publishedAt','')}\n",
    "                comment_data.append(data2)\n",
    "        except HttpError as e:\n",
    "            if e.resp.status == 403:\n",
    "                print(f\"Comments are disabled for video ID: {video_id}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Error fetching comments for video ID: {video_id}, {e}\")\n",
    "    return comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c2fa054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mongodb connection\n",
    "client=pymongo.MongoClient('mongodb://localhost:27017')\n",
    "database=client['youtube_data_harvesting']\n",
    "collection=database['channel_details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "79d48b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_channel_details(channel_id):\n",
    "    ch_details=get_channel_detail(channel_id)\n",
    "    vid_id=get_video_id(channel_id)\n",
    "    vid_details=get_video_detail(vid_id)\n",
    "    com_details=get_comment_detail(vid_id)\n",
    "\n",
    "    database=client['youtube_data_harvesting']\n",
    "    collection=database['channel_details']\n",
    "    collection.insert_one({\"channel_information\":ch_details,\n",
    "                           \"video_information\":vid_details,\n",
    "                           \"comment_information\":com_details})\n",
    "    return \"Channel informations uploaded successfully\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d81c6624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mysql connection\n",
    "myconnection=pymysql.connect(host=\"localhost\",user=\"root\", password='Hari@hds1234#')\n",
    "cur=myconnection.cursor()\n",
    "cur.execute('CREATE DATABASE IF NOT EXISTS youtube_harvesting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ed0b82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating channel table\n",
    "def channel_table(channel_iD):\n",
    "    myconnection=pymysql.connect(host=\"localhost\",user=\"root\", password='Hari@hds1234#',database=\"youtube_harvesting\")\n",
    "    cur=myconnection.cursor()\n",
    "    cur.execute('CREATE DATABASE IF NOT EXISTS youtube_harvesting')\n",
    "    sql_channel=cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS channel_details(channel_name varchar(50),\n",
    "                Channel_Id VARCHAR(100) PRIMARY KEY,\\\n",
    "                Subscription_Count INT,\\\n",
    "                Channel_Views BIGINT,\\\n",
    "                Channel_Description TEXT,\\\n",
    "                Video_count INT,\\\n",
    "                Playlist_id VARCHAR(100))\"\"\")\n",
    "    myconnection.commit()\n",
    "    chan_dbs = []\n",
    "    database = client['youtube_data_harvesting']\n",
    "    collection = database['channel_details']\n",
    "    for ch_data in collection.find({},{\"_id\": 0,\"channel_information\":1}):\n",
    "        chan_dbs.append(ch_data['channel_information'])\n",
    "\n",
    "    ID=channel_iD\n",
    "    new_chan_dbs=[]\n",
    "    for item in chan_dbs:\n",
    "        if item.get('Channel_ID') == ID:\n",
    "            new_chan_dbs.append(item)\n",
    "    chan_df=pd.DataFrame(new_chan_dbs)\n",
    "\n",
    "    \n",
    "    for index,row in chan_df.iterrows():   \n",
    "        add_query=(\"\"\"insert into channel_details(channel_name,\n",
    "        Channel_Id,\n",
    "        Subscription_Count,\n",
    "        Channel_Views,\n",
    "        Channel_Description,\n",
    "        Video_count,\n",
    "        Playlist_id)\n",
    "        values(%s,%s,%s,%s,%s,%s,%s)\"\"\")\n",
    "\n",
    "        values=(row['channel_name'],\n",
    "                row['Channel_ID'],\n",
    "                row['Subscription_Count'],\n",
    "                row['Channel_Views'],\n",
    "                row['Channel_Description'],\n",
    "                row['Video_count'],\n",
    "                row['Playlist_id'])\n",
    "        cur.execute(add_query,values)\n",
    "        myconnection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d232aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating video table\n",
    "def video_table(channel_iD):\n",
    "    myconnection=pymysql.connect(host=\"localhost\",user=\"root\", password='Hari@hds1234#',database=\"youtube_harvesting\")\n",
    "    cur=myconnection.cursor()\n",
    "    cur.execute('CREATE DATABASE IF NOT EXISTS youtube_harvesting')\n",
    "    sql_video=cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS video_details(Channel_Id varchar(100),Channel_Name varchar(100),Video_Id varchar(100) PRIMARY KEY,\n",
    "                Video_Name VARCHAR(500) ,\\\n",
    "                Video_Description TEXT,\\\n",
    "                Published_Date DATETIME,\\\n",
    "                View_Count INT,\\\n",
    "                Like_Count INT,\\\n",
    "                Favorite_Count INT,\\\n",
    "                Comment INT,\\\n",
    "                Duration TIME,\\\n",
    "                Thumbnail VARCHAR(100),\n",
    "                Caption_status varchar(50))\"\"\")\n",
    "    myconnection.commit()\n",
    "    \n",
    "    video_dbs = []\n",
    "    database = client['youtube_data_harvesting']\n",
    "    collection = database['channel_details']\n",
    "    for video_data in collection.find({},{\"_id\": 0,\"video_information\":1}):\n",
    "        for i in range(len(video_data['video_information'])):\n",
    "            video_dbs.append(video_data['video_information'][i])\n",
    "    \n",
    "    ID=channel_iD\n",
    "    new_vid_dbs=[]\n",
    "    for item in video_dbs:\n",
    "        if item.get('Channel_Id') == ID:\n",
    "            new_vid_dbs.append(item)\n",
    "    video_df=pd.DataFrame(new_vid_dbs)\n",
    "    \n",
    "    video_df['Published_Date']=pd.to_datetime(video_df['Published_Date'])\n",
    "    video_df['Duration'] = pd.to_timedelta(video_df['Duration']).dt.total_seconds()\n",
    "    video_df['Duration'] = pd.to_datetime(video_df['Duration'], unit='s').dt.strftime('%H:%M:%S')\n",
    "    video_df = video_df.where(pd.notnull(video_df), None)\n",
    "    \n",
    "    \n",
    "\n",
    "    for index,row in video_df.iterrows():\n",
    "        add_query=(\"\"\"insert into video_details(Channel_Id,\n",
    "        Channel_Name,\n",
    "        Video_Id,\n",
    "        Video_Name,\n",
    "        Video_Description,\n",
    "        Published_Date,\n",
    "        View_Count,\n",
    "        Like_Count,\n",
    "        Favorite_Count,\n",
    "        Comment,\n",
    "        Duration,\n",
    "        Thumbnail,\n",
    "        Caption_status)\n",
    "        values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\"\")\n",
    "\n",
    "        values=(row['Channel_Id'],\n",
    "                row['Channel_Name'],\n",
    "                row['Video_Id'],\n",
    "                row['Video_Name'],\n",
    "                row['Video_Description'],\n",
    "                row['Published_Date'],\n",
    "                row['View_Count'],\n",
    "                row['Like_Count'],\n",
    "                row['Favorite_Count'],\n",
    "                row['Comment'],\n",
    "                row['Duration'],\n",
    "                row['Thumbnail'],\n",
    "                row['Caption_status'])\n",
    "        cur.execute(add_query,values)\n",
    "        myconnection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "37d6fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating comment table\n",
    "def comment_table(channel_iD):\n",
    "    myconnection=pymysql.connect(host=\"localhost\",user=\"root\", password='Hari@hds1234#',database=\"youtube_harvesting\")\n",
    "    cur=myconnection.cursor()\n",
    "    cur.execute('CREATE DATABASE IF NOT EXISTS youtube_harvesting')\n",
    "    sql_comment=cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS comment_details(Channel_Id varchar(100),comment_id varchar(100) PRIMARY KEY,Video_id varchar(50),\n",
    "                Comment_Text TEXT,\\\n",
    "                Comment_Author TEXT,\\\n",
    "                Comment_PublishedAt DATETIME)\"\"\")\n",
    "    myconnection.commit()\n",
    "    comment_dbs = []\n",
    "    database = client['youtube_data_harvesting']\n",
    "    collection = database['channel_details']\n",
    "    for comment_data in collection.find({},{\"_id\": 0,\"comment_information\":1}):\n",
    "        for i in range(len(comment_data['comment_information'])):\n",
    "            comment_dbs.append(comment_data['comment_information'][i])\n",
    "    ID=channel_iD      \n",
    "    new_com_dbs=[]\n",
    "    for item in comment_dbs:\n",
    "        if item.get('Channel_Id') == ID:\n",
    "            new_com_dbs.append(item)\n",
    "    comment_df=pd.DataFrame(new_com_dbs)      \n",
    "    comment_df=pd.DataFrame(comment_dbs)\n",
    "    comment_df['Comment_PublishedAt']=pd.to_datetime(comment_df['Comment_PublishedAt'])\n",
    "    \n",
    "    for index,row in comment_df.iterrows():\n",
    "            try:\n",
    "                add_query=(\"\"\"insert into comment_details(Channel_Id,\n",
    "                comment_id,\n",
    "                Video_id,\n",
    "                Comment_Text,\n",
    "                Comment_Author,\n",
    "                Comment_PublishedAt)\n",
    "                values(%s,%s,%s,%s,%s,%s)\"\"\")\n",
    "\n",
    "                values=(row['Channel_Id'],\n",
    "                        row['comment_id'],\n",
    "                        row['Video_id'],\n",
    "                        row['Comment_Text'],\n",
    "                        row['Comment_Author'],\n",
    "                        row['Comment_PublishedAt'])\n",
    "                cur.execute(add_query,values)\n",
    "                myconnection.commit()\n",
    "            except pymysql.IntegrityError as e:\n",
    "                print(\"Skipping duplicate entry:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f195ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_tables(channel_iD):\n",
    "    channel_table(channel_iD)\n",
    "    video_table(channel_iD)\n",
    "    comment_table(channel_iD)\n",
    "\n",
    "    return \"All tables are created\"\n",
    "    result=all_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba893f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlit\n",
    "st.set_page_config(page_title= \"Youtube Data Harvesting and Warehousing|\",\n",
    "                   layout= \"wide\",\n",
    "                   initial_sidebar_state= \"expanded\")\n",
    "st.title(\":red[YOUTUBE DATA HARVESTING AND WAREHOUSING]\")\n",
    "tab1, tab2, tab3 = st.tabs([\"Data Collection\", \"Migrating Data to MySql\",\"Data Analysis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "97ca140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_channel_details():\n",
    "    chan_dbs = []\n",
    "    database = client['youtube_data_harvesting']\n",
    "    collection = database['channel_details']\n",
    "    for ch_data in collection.find({},{\"_id\": 0,\"channel_information\":1}):\n",
    "        chan_dbs.append(ch_data['channel_information'])\n",
    "\n",
    "    df=st.dataframe(chan_dbs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7ae51702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_video_details():\n",
    "    video_dbs = []\n",
    "    database = client['youtube_data_harvesting']\n",
    "    collection = database['channel_details']\n",
    "    for video_data in collection.find({},{\"_id\": 0,\"video_information\":1}):\n",
    "        for i in range(len(video_data['video_information'])):\n",
    "            video_dbs.append(video_data['video_information'][i])\n",
    "    df2=st.dataframe(video_dbs)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "65383726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_comment_details():\n",
    "    comment_dbs = []\n",
    "    database = client['youtube_data_harvesting']\n",
    "    collection = database['channel_details']\n",
    "    for comment_data in collection.find({},{\"_id\": 0,\"comment_information\":1}):\n",
    "        for i in range(len(comment_data['comment_information'])):\n",
    "            comment_dbs.append(comment_data['comment_information'][i])\n",
    "\n",
    "    df3=st.dataframe(comment_dbs)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4efc4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tab1:\n",
    "    #st.markdown(style)\n",
    "    st.subheader(\"Enter the YouTube Channel ID\")    \n",
    "    channel_Id=st.text_input('Enter the ID:')\n",
    "    result = st.success(\"Input accepted: {}\".format(channel_Id)) if len(channel_Id) == 24 else (st.error(\"Input should be exactly 24 characters long.\") or None)\n",
    "    if st.button(\"Collect and store data\"):\n",
    "        chan_ids = []\n",
    "        database = client['youtube_data_harvesting']\n",
    "        collection = database['channel_details']\n",
    "        for ch_data in collection.find({},{\"_id\": 0,\"channel_information\":1}):\n",
    "            chan_ids.append(ch_data['channel_information']['Channel_ID'])\n",
    "        if channel_Id in chan_ids:\n",
    "            st.success('The channel_id already exist')\n",
    "        else:\n",
    "            insert=all_channel_details(channel_Id)\n",
    "            st.success(insert)\n",
    "\n",
    "    View=st.checkbox('View data collections')\n",
    "    if View:     \n",
    "        show_table=st.selectbox(\"Select the collection data \", (\"CHANNELS\", \"VIDEOS\",\"COMMENTS\"))\n",
    "        if show_table==\"CHANNELS\":\n",
    "            view_channel_details()\n",
    "        elif show_table==\"VIDEOS\":\n",
    "            view_video_details()\n",
    "        elif show_table==\"COMMENTS\":\n",
    "            view_comment_details()\n",
    "\n",
    "with tab2:\n",
    "    st.subheader(\"Transfer the data to MySql\")\n",
    "    channel_ID=st.text_input('Enter a Channel ID Stored in Database:',key=\"channel_id_input\")\n",
    "    result2 = st.success(\"Input accepted: {}\".format(channel_ID)) if len(channel_ID) == 24 else (st.error(\"Input should be exactly 24 characters long.\") or None)\n",
    "    \n",
    "    if st.button(\"Migrate to MySql\"):\n",
    "        tables=all_tables(channel_ID)\n",
    "        st.success(tables)\n",
    "\n",
    "   \n",
    "with tab3:\n",
    "    st.subheader(\"Sql Queries\")\n",
    "    view2=st.checkbox(\"View Query\")\n",
    "    if view2:\n",
    "        myconnection=pymysql.connect(host=\"localhost\",user=\"root\", password='Hari@hds1234#',database=\"youtube_harvesting\")\n",
    "        cur=myconnection.cursor()\n",
    "\n",
    "\n",
    "        question=st.selectbox(\"Select your question\",(\"What are the names of all the videos and their corresponding channels?\",\n",
    "                                                    \"Which channels have the most number of videos, and how many videos do they have?\",\n",
    "                                                    \"What are the top 10 most viewed videos and their respective channels?\",\n",
    "                                                    \"How many comments were made on each video, and what are their corresponding video names?\",\n",
    "                                                    \"Which videos have the highest number of likes, and what are their corresponding channel names?\",\n",
    "                                                    \"What is the total number of views for each channel, and what are their corresponding channel names?\",\n",
    "                                                    \"What are the names of all the channels that have published videos in the year 2022?\",\n",
    "                                                    \"What is the average duration of all videos in each channel, and what are their corresponding channel names?\",\n",
    "                                                    \"Which videos have the highest number of comments, and what are their corresponding channel names?\"))\n",
    "\n",
    "        if question==\"What are the names of all the videos and their corresponding channels?\":\n",
    "            query1=\"select Video_Name,Channel_Name from video_details\"\n",
    "            cur.execute(query1)\n",
    "            myconnection.commit()\n",
    "            q1=cur.fetchall()\n",
    "            df1=pd.DataFrame(q1,columns=[\"video_name\",\"channel_name\"])\n",
    "            st.write(df1)\n",
    "            \n",
    "        elif question==\"Which channels have the most number of videos, and how many videos do they have?\":  \n",
    "            query2=\"select channel_name,Video_count from channel_details order by Video_count desc\"\n",
    "            cur.execute(query2)\n",
    "            myconnection.commit()\n",
    "            q2=cur.fetchall()\n",
    "            df2=pd.DataFrame(q2,columns=[\"channel_name\",\"video_count\"])\n",
    "            st.write(df2)\n",
    "\n",
    "        elif question==\"What are the top 10 most viewed videos and their respective channels?\":\n",
    "            query3=\"select Channel_Name,Video_Name,View_Count from video_details order by view_count desc limit 10\"\n",
    "            cur.execute(query3)\n",
    "            myconnection.commit()\n",
    "            q3=cur.fetchall()\n",
    "            df3=pd.DataFrame(q3,columns=[\"channel_name\",\"video_name\",\"view_count\"])\n",
    "            st.write(df3)\n",
    "            \n",
    "        elif question==\"How many comments were made on each video, and what are their corresponding video names?\":\n",
    "            query4=\"select Video_Name,Comment from video_details order by Comment desc\"\n",
    "            cur.execute(query4)\n",
    "            myconnection.commit()\n",
    "            q4=cur.fetchall()\n",
    "            df4=pd.DataFrame(q4,columns=[\"video_name\",\"number_of_comments\"])\n",
    "            st.write(df4)\n",
    "            \n",
    "        elif question==\"Which videos have the highest number of likes, and what are their corresponding channel names?\":\n",
    "            query5=\"select Channel_Name,Video_Name,Like_Count from video_details order by Like_Count desc\"\n",
    "            cur.execute(query5)\n",
    "            myconnection.commit()\n",
    "            q5=cur.fetchall()\n",
    "            df5=pd.DataFrame(q5,columns=[\"channel_name\",\"video_name\",\"like_count\"])\n",
    "            st.write(df5)\n",
    "            \n",
    "        elif question==\"What is the total number of views for each channel, and what are their corresponding channel names?\":\n",
    "            query6=\"select channel_name,Channel_Views from channel_details order by Channel_Views desc\"\n",
    "            cur.execute(query6)\n",
    "            myconnection.commit()\n",
    "            q6=cur.fetchall()\n",
    "            df6=pd.DataFrame(q6,columns=[\"channel_name\",\"channel_views\"])\n",
    "            st.write(df6)\n",
    "\n",
    "        elif question==\"What are the names of all the channels that have published videos in the year 2022?\":\n",
    "            query7=\"select Channel_Name,Video_Name,Published_Date from video_details where extract(year from Published_Date)=2022\"\n",
    "            cur.execute(query7)\n",
    "            myconnection.commit()\n",
    "            q7=cur.fetchall()\n",
    "            df7=pd.DataFrame(q7,columns=[\"channel_name\",\"video_name\",\"published_year\"])\n",
    "            st.write(df7)\n",
    "\n",
    "        elif question==\"What is the average duration of all videos in each channel, and what are their corresponding channel names?\":\n",
    "            query8=\"SELECT Channel_Name, AVG(Duration) AS Avg_duration FROM video_details GROUP BY Channel_Name\"\n",
    "            cur.execute(query8)\n",
    "            myconnection.commit()\n",
    "            q8=cur.fetchall()\n",
    "            df8=pd.DataFrame(q8,columns=[\"channel_name\",\"Avg_duration\"])\n",
    "            st.write(df8)\n",
    "\n",
    "        elif question==\"Which videos have the highest number of comments, and what are their corresponding channel names?\":\n",
    "            query9=\"select Channel_Name,Video_Name,Comment from video_details order by Comment desc\"\n",
    "            cur.execute(query9)\n",
    "            myconnection.commit()\n",
    "            q9=cur.fetchall()\n",
    "            df10=pd.DataFrame(q9,columns=[\"channel_name\",\"video_name\",\"highest_no_of_comments\"])\n",
    "            st.write(df10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f8745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ed4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
